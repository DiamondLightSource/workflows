apiVersion: argoproj.io/v1alpha1
kind: ClusterWorkflowTemplate
metadata:
  name: pytorch-example
spec:
  entrypoint: workflow-entry
  arguments:
    parameters:
      - name: size
        value: 1024
  volumeClaimTemplates:
    - metadata:
        name: tmpdir
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 16Gi
        storageClassName: netapp

  templates:
    - name: install-dependencies
      script:
        image: python:3.10
        volumeMounts:
          - name: tmpdir
            mountPath: /tmp
        command: [bash]
        source: |
          echo "creating a venv and installing dependencies."
          python -m venv /tmp/venv
          /tmp/venv/bin/pip install --no-cache-dir numpy Pillow
          echo "done"

    - name: matrix-multiplication
      inputs: 
        parameters:
          - name: size
            value: 1024
      script: 
        image: pytorch/pytorch
        volumeMounts:
          - name: tmpdir
            mountPath: /tmp
        command: ["python"]
        source: |
          import torch
          import numpy as np
          assert torch.cuda.is_available(), "Not running on GPU"
          print(f"Running on GPU")
          size = {{inputs.parameters.size}}
          mat_a = torch.rand(size,size,device="cuda")
          mat_b = torch.rand(size,size,device="cuda")
          product = (mat_a @ mat_b)
          norm_array = 255 * (product - product.min()) / product.max()
          np.save("/tmp/output.npy", norm_array.detach().cpu().numpy())
          print("Result saved to /tmp/output.npy")

    - name: generate-image
      script:
        image: python:3.10
        volumeMounts:
        - name: tmpdir
          mountPath: /tmp
        command: ["/tmp/venv/bin/python"]
        source: |
          import os.path
          import numpy as np
          from PIL import Image
          array = np.load("/tmp/output.npy")
          print(f"Loaded array with shape: {array.shape}")
          image = Image.fromarray(array).convert("L")
          print("Saving image...")
          image.save("/tmp/image.png", mode="L")
          if os.path.isfile("/tmp/image.png"):
            print("Image saved at /tmp/image.png")
      outputs:
        artifacts:
          - name: "png-file"
            path: "/tmp/image.png"
            archive:
              none: {}

    - name: workflow-entry
      dag: 
        tasks:
          - name: install-dependencies
            template: install-dependencies
          
          - name: matrix-multiplication
            template: matrix-multiplication
            arguments:
              parameters:
                - name: size
                  value: "{{workflow.parameters.size}}"

          - name: generate-image
            template: generate-image
            dependencies: [install-dependencies, matrix-multiplication]
      podSpecPatch: |
        containers:
          - name: main
            resources:
              requests:
                cpu: 1
                memory: 16Gi
                nvidia.com/gpu: 1
              limits:
                cpu: 1
                memory: 16Gi
                nvidia.com/gpu: 1
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      - key: nodetype
        operator: Equal
        value: gpu
        effect: NoSchedule
      - key: nodegroup
        operator: Equal
        value: workflows
        effect: NoSchedule
      nodeSelector: 
        nodetype: gpu
